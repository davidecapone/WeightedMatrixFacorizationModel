{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loss: 0.151, iteration: 1/100\n",
      "Loss: 0.130, iteration: 2/100\n",
      "Loss: 0.119, iteration: 3/100\n",
      "Loss: 0.111, iteration: 4/100\n",
      "Loss: 0.106, iteration: 5/100\n",
      "Loss: 0.102, iteration: 6/100\n",
      "Loss: 0.098, iteration: 7/100\n",
      "Loss: 0.095, iteration: 8/100\n",
      "Loss: 0.093, iteration: 9/100\n",
      "Loss: 0.091, iteration: 10/100\n",
      "Loss: 0.089, iteration: 11/100\n",
      "Loss: 0.087, iteration: 12/100\n",
      "Loss: 0.085, iteration: 13/100\n",
      "Loss: 0.084, iteration: 14/100\n",
      "Loss: 0.082, iteration: 15/100\n",
      "Loss: 0.081, iteration: 16/100\n",
      "Loss: 0.080, iteration: 17/100\n",
      "Loss: 0.079, iteration: 18/100\n",
      "Loss: 0.078, iteration: 19/100\n",
      "Loss: 0.077, iteration: 20/100\n",
      "Loss: 0.076, iteration: 21/100\n",
      "Loss: 0.075, iteration: 22/100\n",
      "Loss: 0.075, iteration: 23/100\n",
      "Loss: 0.074, iteration: 24/100\n",
      "Loss: 0.074, iteration: 25/100\n",
      "Loss: 0.073, iteration: 26/100\n",
      "Loss: 0.072, iteration: 27/100\n",
      "Loss: 0.072, iteration: 28/100\n",
      "Loss: 0.072, iteration: 29/100\n",
      "Loss: 0.071, iteration: 30/100\n",
      "Loss: 0.071, iteration: 31/100\n",
      "Loss: 0.070, iteration: 32/100\n",
      "Loss: 0.070, iteration: 33/100\n",
      "Loss: 0.070, iteration: 34/100\n",
      "Loss: 0.070, iteration: 35/100\n",
      "Loss: 0.069, iteration: 36/100\n",
      "Loss: 0.069, iteration: 37/100\n",
      "Loss: 0.069, iteration: 38/100\n",
      "Loss: 0.069, iteration: 39/100\n",
      "Loss: 0.069, iteration: 40/100\n",
      "Loss: 0.068, iteration: 41/100\n",
      "Loss: 0.068, iteration: 42/100\n",
      "Loss: 0.068, iteration: 43/100\n",
      "Loss: 0.068, iteration: 44/100\n",
      "Loss: 0.068, iteration: 45/100\n",
      "Loss: 0.068, iteration: 46/100\n",
      "Loss: 0.068, iteration: 47/100\n",
      "Loss: 0.067, iteration: 48/100\n",
      "Loss: 0.067, iteration: 49/100\n",
      "Loss: 0.067, iteration: 50/100\n",
      "Loss: 0.067, iteration: 51/100\n",
      "Loss: 0.067, iteration: 52/100\n",
      "Loss: 0.067, iteration: 53/100\n",
      "Loss: 0.067, iteration: 54/100\n",
      "Loss: 0.067, iteration: 55/100\n",
      "Loss: 0.067, iteration: 56/100\n",
      "Loss: 0.067, iteration: 57/100\n",
      "Loss: 0.067, iteration: 58/100\n",
      "Loss: 0.067, iteration: 59/100\n",
      "Loss: 0.067, iteration: 60/100\n",
      "Loss: 0.067, iteration: 61/100\n",
      "Loss: 0.067, iteration: 62/100\n",
      "Loss: 0.067, iteration: 63/100\n",
      "Loss: 0.066, iteration: 64/100\n",
      "Loss: 0.066, iteration: 65/100\n",
      "Loss: 0.066, iteration: 66/100\n",
      "Loss: 0.066, iteration: 67/100\n",
      "Loss: 0.066, iteration: 68/100\n",
      "Loss: 0.066, iteration: 69/100\n",
      "Loss: 0.066, iteration: 70/100\n",
      "Loss: 0.066, iteration: 71/100\n",
      "Loss: 0.066, iteration: 72/100\n",
      "Loss: 0.066, iteration: 73/100\n",
      "Loss: 0.066, iteration: 74/100\n",
      "Loss: 0.066, iteration: 75/100\n",
      "Loss: 0.066, iteration: 76/100\n",
      "Loss: 0.066, iteration: 77/100\n",
      "Loss: 0.066, iteration: 78/100\n",
      "Loss: 0.066, iteration: 79/100\n",
      "Loss: 0.066, iteration: 80/100\n",
      "Loss: 0.066, iteration: 81/100\n",
      "Loss: 0.066, iteration: 82/100\n",
      "Loss: 0.066, iteration: 83/100\n",
      "Loss: 0.066, iteration: 84/100\n",
      "Loss: 0.066, iteration: 85/100\n",
      "Loss: 0.066, iteration: 86/100\n",
      "Loss: 0.066, iteration: 87/100\n",
      "Loss: 0.066, iteration: 88/100\n",
      "Loss: 0.066, iteration: 89/100\n",
      "Loss: 0.066, iteration: 90/100\n",
      "Loss: 0.066, iteration: 91/100\n",
      "Loss: 0.066, iteration: 92/100\n",
      "Loss: 0.066, iteration: 93/100\n",
      "Loss: 0.066, iteration: 94/100\n",
      "Loss: 0.066, iteration: 95/100\n",
      "Loss: 0.066, iteration: 96/100\n",
      "Loss: 0.066, iteration: 97/100\n",
      "Loss: 0.066, iteration: 98/100\n",
      "Loss: 0.066, iteration: 99/100\n",
      "Loss: 0.066, iteration: 100/100\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.wmf import WeightedMatrixFactorization\n",
    "import numpy as np\n",
    "\n",
    "feedback_matrix = np.array([[3, 4, np.nan, 1, np.nan, np.nan, 5, np.nan, np.nan, np.nan],\n",
    "                            [1, 3, np.nan, np.nan, np.nan, 3, np.nan, np.nan, 5, 5],\n",
    "                            [1, np.nan, 1, 4, 4, np.nan, np.nan, np.nan, 3, 4]])\n",
    "\n",
    "wmf = WeightedMatrixFactorization(\n",
    "    feedback_matrix, \n",
    "    n_latents=100,\n",
    "    n_iter=100,\n",
    "    lambda_reg=0.05\n",
    "    )\n",
    "\n",
    "hist = wmf.fit(method='WALS', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "print(hist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhitegrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# plot the history of the loss function\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39mhist\u001b[38;5;241m.\u001b[39mkeys(), y\u001b[38;5;241m=\u001b[39m\u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "# plot the history of the loss function\n",
    "\n",
    "sns.lineplot(x=hist.keys(), y=hist['loss'])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
