{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender system\n",
    "In this notebook, we will leverage the trained Weighted Matrix Factorization model to make recommendations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wmfact import WeightedMatrixFactorization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model\n",
    "model = WeightedMatrixFactorization.load('./models/wmf_wals_nlat270_niter16_lambdareg0.02.pkl')\n",
    "#usr_emb, item_emb = model.get_embeddings() # the user and item embeddings\n",
    "\n",
    "# Load the data\n",
    "feedbacks = np.load('./data/feedbacks.npy') # the feedbacks matrix that was used to train the model\n",
    "movies = pd.read_csv('data/movies.csv') # contains info about each movie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "unknown opcode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mget_embeddings()\n",
      "\u001b[1;31mSystemError\u001b[0m: unknown opcode"
     ]
    }
   ],
   "source": [
    "model.get_embeddings()\n",
    "#print(users_embedding.shape, items_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cosine similarity metric\n",
    "Cosine similarity is a metric that measures the cosine of the angle between two non-zero vectors in a multi-dimensional space; it computes the cosine of the angle between the two vectors, representing the direction of the vectors regardless of their magnitude.\n",
    "\n",
    "$$ cosine\\_similarity(A, B) = \\frac{A \\cdot B}{||A|| ||B||} $$\n",
    "\n",
    "- $A \\cdot B$ is the dot-product of the two vectors;\n",
    "- $||A||$, $||B||$ are the Euclidian norms (magnitudes) of the two vectors.\n",
    "\n",
    "The cosine similarity returns a value in $[-1,1]$; a value closer to 1 indicates greater similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity( vector1, vector2 ):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "    Formula: similarity = (vector1 . vector2) / (||vector1|| * ||vector2||)\n",
    "    \n",
    "    Parameters:\n",
    "    - vector1 (numpy.ndarray): The first vector.\n",
    "    - vector2 (numpy.ndarray): The second vector.\n",
    "    \n",
    "    Returns:\n",
    "    - similarity (float): The cosine similarity between the two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    similarity = np.dot(vector1, vector2) / (norm_vector1 * norm_vector2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "- Retrieve the user embedding vector corresponding to the user_id from the trained model. This vector represents the user's preferences in the latent space learned by the model.\n",
    "- Determine the indices of items that the user has not rated. These indices represent the items that are potentially eligible for recommendation to the user.\n",
    "- Calculate the cosine similarity between the user embedding vector and the embedding vectors of the unrated items. Cosine similarity measures the cosine of the angle between two vectors and quantifies how similar they are in direction.\n",
    "- Sort the computed similarity scores in descending order to identify the items that are most similar to the user's preferences. These items are potential candidates for recommendation.\n",
    "- Select the top-N items with the highest similarity scores to recommend to the user. These items are considered the most relevant or similar to the user's preferences.\n",
    "- Return the top-N recommended items along with their similarity scores in a pandas DataFrame, where each row represents an item and includes information such as the item's title and the computed similarity percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contentbased_filtering(user_id, model, top_n=10):\n",
    "    \"\"\"\n",
    "    Get the top-n items for a user using content-based filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id (int): The user id.\n",
    "    - model (WeightedMatrixFactorization): The trained model.\n",
    "    - top_n (int): The number of items to recommend.\n",
    "\n",
    "    Returns:\n",
    "    - top_k_movies (pandas.DataFrame): The top-k items.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the user and item embeddings:\n",
    "    users_embedding, items_embedding = model.get_embeddings()\n",
    "\n",
    "    # get the user embedding for the user_id:\n",
    "    user_embedding = users_embedding[user_id]\n",
    "\n",
    "    # get all the items that the user has not rated (the indices of the items):\n",
    "    idx_not_rated = np.where( \n",
    "        np.isnan( feedbacks[user_id] )\n",
    "    )[0]\n",
    "\n",
    "    # compute the similarities between this user and the items that he has not rated:\n",
    "    similarities = np.array([ \n",
    "        cosine_similarity(\n",
    "            vector1 = user_embedding,           # the user embedding\n",
    "            vector2 = items_embedding[idx]      # the item embedding of the idx-th item\n",
    "        ) for idx in idx_not_rated              # iterate over non-rated items\n",
    "    ])\n",
    "\n",
    "    similarities = similarities * 100               # convert to %\n",
    "    similarities = np.round( similarities, 2 )      # round 2 decimal places\n",
    "    top_k = np.argsort(similarities)[::-1][:top_n]  # get the indices of the top-n items\n",
    "    top_k_movies = movies.iloc[top_k]               # get the corresponding movies\n",
    "    top_k_movies = top_k_movies.copy()\n",
    "    top_k_movies['similarity (%)'] = similarities[top_k] # add the similarities to dataframe\n",
    "    return top_k_movies     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, now we can recommend top 10 movies for the user with id = 475:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_movies = contentbased_filtering( user_id = 475, model = model, top_n = 10 )\n",
    "print(top_k_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      title  similarity\n",
      "173          Raiders of the Lost Ark (1981)    0.618102\n",
      "63         Shawshank Redemption, The (1994)    0.589655\n",
      "78                     Fugitive, The (1993)    0.582490\n",
      "49                         Star Wars (1977)    0.579519\n",
      "171         Empire Strikes Back, The (1980)    0.579427\n",
      "175                           Aliens (1986)    0.569882\n",
      "356  One Flew Over the Cuckoo's Nest (1975)    0.567194\n",
      "11               Usual Suspects, The (1995)    0.565332\n",
      "97         Silence of the Lambs, The (1991)    0.560144\n",
      "180               Return of the Jedi (1983)    0.550040\n",
      "143                         Die Hard (1988)    0.549425\n",
      "194                  Terminator, The (1984)    0.548943\n",
      "21                        Braveheart (1995)    0.545214\n",
      "317                 Schindler's List (1993)    0.545053\n",
      "650                            Glory (1989)    0.544800\n",
      "95        Terminator 2: Judgment Day (1991)    0.541405\n",
      "30                      Crimson Tide (1995)    0.540481\n",
      "27                         Apollo 13 (1995)    0.540305\n",
      "190                          Amadeus (1984)    0.539660\n",
      "195               Dead Poets Society (1989)    0.528983\n"
     ]
    }
   ],
   "source": [
    "def collaborative_filtering(user_id, model, top_n=10):\n",
    "    \"\"\" \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    users_embedding, items_embedding = model.get_embeddings()\n",
    "    user_embedding = users_embedding[user_id]\n",
    "\n",
    "    idx_not_rated = np.where( np.isnan(\n",
    "    feedbacks[user_id]) \n",
    "    )[0]\n",
    "\n",
    "    # similarity between this user and all the other users:\n",
    "    similarities = np.array([ \n",
    "    cosine_similarity(\n",
    "        vector1 = users_embedding[idx],\n",
    "        vector2 = user_embedding\n",
    "    ) for idx in range(users_embedding.shape[0])\n",
    "    ])\n",
    "\n",
    "    sorted_indices = np.argsort(similarities)[::-1][:int(0.10*len(similarities))]\n",
    "    sorted_indices = sorted_indices[1:]  # Exclude the target user\n",
    "\n",
    "    # Aggregate preferences of similar users\n",
    "    aggregated_preferences = np.sum(users_embedding[sorted_indices], axis=0)\n",
    "\n",
    "    # Calculate cosine similarity between the target user group and items based on content features\n",
    "    similarities = np.array([ \n",
    "    cosine_similarity(\n",
    "        vector1 = aggregated_preferences,\n",
    "        vector2 = items_embedding[idx]\n",
    "    ) for idx in idx_not_rated\n",
    "    ])\n",
    "\n",
    "    # sort items and similarities together according to content-based similarity in descending order\n",
    "    sorted_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "    recommended_item_indices = idx_not_rated[sorted_indices]\n",
    "    recommended_items_similarities = similarities[sorted_indices]\n",
    "\n",
    "    # a dataframe with the recommended items and their similarities:\n",
    "    recommended_items = movies.iloc[recommended_item_indices]\n",
    "    recommended_items = recommended_items.copy()\n",
    "    recommended_items['similarity'] = recommended_items_similarities\n",
    "\n",
    "    return recommended_items\n",
    "\n",
    "top_k_movies = collaborative_filtering(475, model, 20)\n",
    "print(top_k_movies[['title', 'similarity']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
