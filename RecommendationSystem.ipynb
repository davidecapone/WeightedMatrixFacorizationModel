{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System Using Weighted Matrix Factorization Model\n",
    "In this notebook, we will leverage the trained Weighted Matrix Factorization model to make recommendations. In particular, we will use two different approaches: Collaborative Filtering and Content-Based Filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wmfact import WeightedMatrixFactorization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = WeightedMatrixFactorization.load('./models/wmf_wals_20240206102010.pkl') # the trained model\n",
    "#usr_emb, item_emb = model.get_embeddings() # the user and item embeddings\n",
    "\n",
    "feedbacks = np.load('./data/feedbacks.npy') # the feedbacks matrix that was used to train the model\n",
    "movies = pd.read_csv('data/movies.csv') # contains info about each movie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cosine similarity metric\n",
    "Cosine similarity is a metric that measures the cosine of the angle between two non-zero vectors in a multi-dimensional space; it computes the cosine of the angle between the two vectors, representing the direction of the vectors regardless of their magnitude.\n",
    "\n",
    "$$ cosine\\_similarity(A, B) = \\frac{A \\cdot B}{||A|| ||B||} $$\n",
    "\n",
    "- $A \\cdot B$ is the dot-product of the two vectors;\n",
    "- $||A||$, $||B||$ are the Euclidian norms (magnitudes) of the two vectors.\n",
    "\n",
    "The cosine similarity returns a value in $[-1,1]$; a value closer to 1 indicates greater similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "    Formula: similarity = (vector1 . vector2) / (||vector1|| * ||vector2||)\n",
    "    \n",
    "    Parameters:\n",
    "    - vector1 (numpy.ndarray): The first vector.\n",
    "    - vector2 (numpy.ndarray): The second vector.\n",
    "    \n",
    "    Returns:\n",
    "    - similarity (float): The cosine similarity between the two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    similarity = np.dot(vector1, vector2) / (norm_vector1 * norm_vector2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "- Retrieve the user embedding vector corresponding to the user_id from the trained model. This vector represents the user's preferences in the latent space learned by the model.\n",
    "- Determine the indices of items that the user has not rated. These indices represent the items that are potentially eligible for recommendation to the user.\n",
    "- Calculate the cosine similarity between the user embedding vector and the embedding vectors of the unrated items. Cosine similarity measures the cosine of the angle between two vectors and quantifies how similar they are in direction.\n",
    "- Sort the computed similarity scores in descending order to identify the items that are most similar to the user's preferences. These items are potential candidates for recommendation.\n",
    "- Select the top-N items with the highest similarity scores to recommend to the user. These items are considered the most relevant or similar to the user's preferences.\n",
    "- Return the top-N recommended items along with their similarity scores in a pandas DataFrame, where each row represents an item and includes information such as the item's title and the computed similarity percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       title  similarity (%)\n",
      "135      Mr. Smith Goes to Washington (1939)           39.18\n",
      "923                      White Squall (1996)           37.66\n",
      "523               Great Dictator, The (1940)           34.96\n",
      "353               Wedding Singer, The (1998)           34.70\n",
      "144                Lawnmower Man, The (1992)           34.30\n",
      "487                      Sunset Blvd. (1950)           34.20\n",
      "134             2001: A Space Odyssey (1968)           33.21\n",
      "1100        Six Degrees of Separation (1993)           33.19\n",
      "729   Queen Margot (Reine Margot, La) (1994)           32.86\n",
      "43                  Dolores Claiborne (1994)           32.55\n",
      "172               Princess Bride, The (1987)           32.32\n",
      "601             American in Paris, An (1951)           32.29\n",
      "71                          Mask, The (1994)           32.20\n",
      "469                         Tombstone (1993)           32.10\n",
      "154                     Dirty Dancing (1987)           32.06\n",
      "416                  Parent Trap, The (1961)           31.79\n",
      "49                          Star Wars (1977)           31.38\n",
      "37                           Net, The (1995)           31.31\n",
      "669                    Body Snatchers (1993)           30.91\n",
      "659              Fried Green Tomatoes (1991)           30.67\n"
     ]
    }
   ],
   "source": [
    "def contentbased_filtering(user_id, model, top_n=10):\n",
    "    \"\"\"\n",
    "    Get the top-n items for a user using content-based filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id (int): The user id.\n",
    "    - model (WeightedMatrixFactorization): The trained model.\n",
    "    - top_n (int): The number of items to recommend.\n",
    "\n",
    "    Returns:\n",
    "    - top_k_movies (pandas.DataFrame): The top-k items.\n",
    "    \"\"\"\n",
    "    users_embedding, items_embedding = model.get_embeddings()\n",
    "\n",
    "    # get the user embedding for the user_id:\n",
    "    user_embedding = users_embedding[user_id]\n",
    "\n",
    "    # get all the items that the user has not rated (the indices of the items):\n",
    "    idx_not_rated = np.where( np.isnan(\n",
    "        feedbacks[user_id]\n",
    "    ) )[0]\n",
    "\n",
    "    # compute the similarities between this user and the items that he has not rated:\n",
    "    similarities = np.array([ \n",
    "        cosine_similarity(\n",
    "            vector1 = user_embedding,\n",
    "            vector2 = items_embedding[idx]\n",
    "        ) for idx in idx_not_rated\n",
    "    ])\n",
    "\n",
    "    similarities = similarities * 100\n",
    "    similarities = np.round(similarities, 2)\n",
    "\n",
    "    # order the similarities in descending order and get the top-n items (indices):\n",
    "    top_k = np.argsort(similarities)[::-1][:top_n]\n",
    "\n",
    "    # get the corresponding movies:\n",
    "    top_k_movies = movies.iloc[top_k]\n",
    "\n",
    "    # add also the similarity to the dataframe:\n",
    "    top_k_movies = top_k_movies.copy()\n",
    "    top_k_movies['similarity (%)'] = similarities[top_k]\n",
    "    return top_k_movies\n",
    "\n",
    "user_id = 475\n",
    "top_k_movies = contentbased_filtering(user_id, model, top_n=20)\n",
    "print(top_k_movies[['title', 'similarity (%)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filtering(user_id, model, top_n=10):\n",
    "    \"\"\" \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    users_embedding, items_embedding = model.get_embeddings()\n",
    "    user_embedding = users_embedding[user_id]\n",
    "\n",
    "    idx_not_rated = np.where( np.isnan(\n",
    "    feedbacks[user_id]) \n",
    "    )[0]\n",
    "\n",
    "    # similarity between this user and all the other users:\n",
    "    similarities = np.array([ \n",
    "    cosine_similarity(\n",
    "        vector1 = users_embedding[idx],\n",
    "        vector2 = user_embedding\n",
    "    ) for idx in range(users_embedding.shape[0])\n",
    "    ])\n",
    "\n",
    "    sorted_indices = np.argsort(similarities)[::-1][:int(0.10*len(similarities))]\n",
    "    sorted_indices = sorted_indices[1:]  # Exclude the target user\n",
    "\n",
    "    # Aggregate preferences of similar users\n",
    "    aggregated_preferences = np.sum(users_embedding[sorted_indices], axis=0)\n",
    "\n",
    "    # Calculate cosine similarity between the target user group and items based on content features\n",
    "    similarities = np.array([ \n",
    "    cosine_similarity(\n",
    "        vector1 = aggregated_preferences,\n",
    "        vector2 = items_embedding[idx]\n",
    "    ) for idx in idx_not_rated\n",
    "    ])\n",
    "\n",
    "    # sort items and similarities together according to content-based similarity in descending order\n",
    "    sorted_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "    recommended_item_indices = idx_not_rated[sorted_indices]\n",
    "    recommended_items_similarities = similarities[sorted_indices]\n",
    "\n",
    "    # a dataframe with the recommended items and their similarities:\n",
    "    recommended_items = movies.iloc[recommended_item_indices]\n",
    "    recommended_items = recommended_items.copy()\n",
    "    recommended_items['similarity'] = recommended_items_similarities\n",
    "\n",
    "    return recommended_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      title  similarity\n",
      "173          Raiders of the Lost Ark (1981)    0.605878\n",
      "63         Shawshank Redemption, The (1994)    0.559251\n",
      "78                     Fugitive, The (1993)    0.553518\n",
      "171         Empire Strikes Back, The (1980)    0.551471\n",
      "175                           Aliens (1986)    0.549505\n",
      "49                         Star Wars (1977)    0.543991\n",
      "356  One Flew Over the Cuckoo's Nest (1975)    0.540971\n",
      "11               Usual Suspects, The (1995)    0.539903\n",
      "97         Silence of the Lambs, The (1991)    0.539591\n",
      "143                         Die Hard (1988)    0.531950\n",
      "194                  Terminator, The (1984)    0.529334\n",
      "21                        Braveheart (1995)    0.519917\n",
      "27                         Apollo 13 (1995)    0.519707\n",
      "650                            Glory (1989)    0.513006\n",
      "180               Return of the Jedi (1983)    0.512904\n",
      "195               Dead Poets Society (1989)    0.512353\n",
      "317                 Schindler's List (1993)    0.512107\n",
      "95        Terminator 2: Judgment Day (1991)    0.511714\n",
      "190                          Amadeus (1984)    0.511243\n",
      "30                      Crimson Tide (1995)    0.508279\n"
     ]
    }
   ],
   "source": [
    "top_k_movies = collaborative_filtering(475, model, 20)\n",
    "print(top_k_movies[['title', 'similarity']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
